# EnsembleExploration
- Explainable AI involves two parts: intrinsic explainability (IE) and extrinsic explainability (EE).
- It is hard to explain the predictions of LLM's because they are made using neural networks which are considered as black boxes.
- Intrinsic explainability is used by the developers for LLMs include attention-based methods and saliency methods
- Attention base methods visualize how the model attends to words in context and neuron visualization for deeper insights.
- Saliency methods, such as gradient-based, propagation-based, and occlusion-based, tells us the importance of input on the model's output.
- Extrinsic explainability is crucial for end users. it involves connecting LLMs to dynamic knowledge bases to provide up-to-date information.

<br>resources: <br>
https://mohitmayank.medium.com/explainable-ai-language-models-b4b75f56bfe2 <br>
https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html <br>
https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1424 <br>
